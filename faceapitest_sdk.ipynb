{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('faceapienv': conda)"
  },
  "interpreter": {
   "hash": "d4d5f78bbde91a6ea14e0ddc815b613cd99843b4fe00fe4c0ac7026767a7eef3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "ENDPOINT = ''\n",
    "img = ''\n",
    "face_client = FaceClient(ENDPOINT,CognitiveServicesCredentials(API_KEY))"
   ]
  },
  {
   "source": [
    "# Face APIの仕様について\n",
    "こちらのリンクを参照\n",
    "https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices/faceapi?view=azure-python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Person group: 1372d973-c5af-4e0b-9189-402bda027293\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Create Person\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, \"Child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.face.models._models_py3.PersonGroup at 0x1efb66144c0>,\n",
       " <azure.cognitiveservices.vision.face.models._models_py3.PersonGroup at 0x1efb6cce400>]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "face_client.person_group.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.face.models._models_py3.Person at 0x1efb65e4ee0>,\n",
       " <azure.cognitiveservices.vision.face.models._models_py3.Person at 0x1efb65e4d90>,\n",
       " <azure.cognitiveservices.vision.face.models._models_py3.Person at 0x1efb6cce220>]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "face_client.person_group_person.list(PERSON_GROUP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# 学習用画像ファイルは\"images/\"に格納されているため移動\n",
    "os.chdir('images/')\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"w\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"m\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"ch\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training the person group...\n",
      "Training status: running.\n",
      "\n",
      "TrainingStatusType.running\n",
      "Training status: succeeded.\n",
      "\n",
      "TrainingStatusType.succeeded\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    print(training_status.status)\n",
    "\n",
    "    # training_statusがsucceededになったら終了\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    # training_status==faildでメッセージを出して終了\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\koishizu\\\\OneDrive - Microsoft\\\\日本マイクロソフト\\\\Demo_Material\\\\faceapi\\\\images'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pausing for 60 seconds to avoid triggering rate limit on free account...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image_array = glob.glob('test-image-person-group.jpg')\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "print('Pausing for 60 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (60)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance.\n",
    "# 画像に写っている顔の検出⇒複数個の可能性があるため配列\n",
    "faces = face_client.face.detect_with_stream(image, detection_model='detection_03')\n",
    "for face in faces:\n",
    "    # facesとしてリストが返ってくるため、各インスタンスのface_idをリストに格納\n",
    "    face_ids.append(face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['022d0d34-3e31-4b24-9e01-3851fb69fe97', 'f0c1a4ef-6112-4c35-a665-739158d43d93']\n",
      "[<azure.cognitiveservices.vision.face.models._models_py3.IdentifyResult object at 0x000001EFBA074490>, <azure.cognitiveservices.vision.face.models._models_py3.IdentifyResult object at 0x000001EFBA074A00>]\n",
      "Identifying faces in test-image-person-group.jpg\n",
      "Plausible person is c1dde8f8-1cd6-4078-8ce6-ba222433e631.\n",
      "Man\n",
      "Person for face ID 022d0d34-3e31-4b24-9e01-3851fb69fe97 is identified in test-image-person-group.jpg with a confidence of 0.92235.\n",
      "Plausible person is dcaa2f22-50de-4ad2-a851-30570bcdac1a.\n",
      "Woman\n",
      "Person for face ID f0c1a4ef-6112-4c35-a665-739158d43d93 is identified in test-image-person-group.jpg with a confidence of 0.93315.\n"
     ]
    }
   ],
   "source": [
    "# Identify faces\n",
    "# テスト画像から検出したface_idのリストを用いて、特定グループ内に同一人物がいるか識別\n",
    "# グループ指定にPERSON_GROUP_IDを利用\n",
    "print(face_ids)\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print(results)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "    if len(person.candidates) > 0:\n",
    "        print('Plausible person is {}.'.format(person.candidates[0].person_id))\n",
    "        print(face_client.person_group_person.get(person_group_id=PERSON_GROUP_ID,person_id=person.candidates[0].person_id).name)\n",
    "        print('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence)) # Get topmost confidence score\n",
    "    else:\n",
    "        print('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}